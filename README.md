# SynapseForge â€” Multi-Model Collaborative Intelligence Engine

> **MIT Application Project** by Samrisht

SynapseForge fuses multiple AI models into a single collaborative intelligence engine. Unlike debate-style systems where models argue against each other, SynapseForge makes models **work together** â€” each contributing unique strengths to produce answers that are demonstrably superior to any single model.

## ğŸ§  Core Concept

Traditional multi-model systems pit AI models against each other in debate. SynapseForge takes a fundamentally different approach:

- **Collaborative, not competitive** â€” Models complement each other's knowledge
- **Specialized roles** â€” Contributors, Verifiers, Stress-Testers, and a final Synthesizer
- **Cross-validation** â€” Claims are verified across multiple models for reliability
- **Consensus detection** â€” Early convergence stops unnecessary rounds, saving cost
- **Provider-agnostic** â€” Integrate OpenAI, Google Gemini, Anthropic Claude, or any model with an API key

## âš¡ Quick Start

### Web Interface (Recommended)
```bash
pip install -r requirements.txt
python server.py
```
Then open **http://localhost:5000** in your browser.

### Streamlit Interface (Legacy)
```bash
streamlit run app.py
```

## ğŸ”‘ API Key Setup

Enter your API keys directly in the web interface, or create a `.env` file:
```env
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=AIza...
ANTHROPIC_API_KEY=sk-ant-...
```

## ğŸ­ Demo Mode

Don't have API keys? Select the **Demo** preset to use mock agents for a zero-cost demonstration of the platform.

## ğŸ—ï¸ Architecture

```
SynapseForge/
â”œâ”€â”€ server.py                    # Flask web server
â”œâ”€â”€ app.py                       # Streamlit interface (legacy)
â”œâ”€â”€ templates/index.html         # Modern web UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ styles.css               # Design system
â”‚   â””â”€â”€ app.js                   # Frontend logic
â”œâ”€â”€ debate_app/
â”‚   â”œâ”€â”€ agents/providers.py      # Multi-provider model agents
â”‚   â””â”€â”€ core/
â”‚       â”œâ”€â”€ base.py              # Agent base classes
â”‚       â”œâ”€â”€ prompts.py           # Collaborative system prompts
â”‚       â””â”€â”€ pricing.py           # Cost estimation
â””â”€â”€ requirements.txt
```

## ğŸ¤– Supported Models

| Provider | Models | Roles |
|----------|--------|-------|
| **OpenAI** | GPT-4o, GPT-4o mini, GPT-3.5 Turbo | Contributor, Judge, Verifier, Stress-Tester |
| **Google** | Gemini 1.5 Pro, Gemini 1.5 Flash | Contributor, Judge, Verifier, Stress-Tester |
| **Anthropic** | Claude 3 Opus, Claude 3 Haiku | Contributor, Judge, Verifier, Stress-Tester |
| **Mock** | Various mock agents | All roles (free demo) |

## ğŸ“Š Features

- **Studio** â€” Configure your model team, set budgets, and run collaborative synthesis
- **Synthesis Feed** â€” Real-time round-by-round transcript of model collaboration
- **Analytics** â€” Cost tracking, token usage, consensus trajectory, provider cost breakdown
- **Preset Configs** â€” Balanced, Rigorous, or Demo mode with one click
- **Export** â€” Download full run data as JSON

## ğŸ”¬ How It Works

1. **You ask a question** â€” Complex research queries work best
2. **Models collaborate** â€” Each model independently analyzes the question, then refines based on others' contributions
3. **Verification** â€” Optional verification agent cross-checks factual claims
4. **Stress-testing** â€” Optional adversarial agent tests edge cases
5. **Synthesis** â€” A judge model fuses all contributions into a single, superior answer
6. **Output** â€” You receive an answer that leverages the collective intelligence of multiple models

## ğŸ“ˆ Why Multi-Model Collaboration?

- **Reduces hallucination** â€” Cross-validation catches errors single models miss
- **Broader knowledge** â€” Different models have different training data strengths
- **Higher reliability** â€” Consensus-based answers are more trustworthy
- **Cost-efficient** â€” Early convergence detection prevents unnecessary API calls

---

*Built for MIT Application Â· 2026*
